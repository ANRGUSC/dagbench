id: ml.gpt2_tensor_sh12_prefill
name: GPT-2 Tensor DAG Sh12 Prefill
description: 'Prefill phase for GPT-2 request handling: run once on the full prompt
  to build KV cache. This workflow profiles q_len=128, kv_len=128. GPT-2 tensor DAG
  with Sh=12 shards per transformer layer. Task costs are measured compute_time_ms
  from dagprofiler; dependency sizes are measured bytes.'
domains:
- ml-pipeline
- edge-computing
provenance:
  source: GPT-2 Hugging Face implementation profiled via dagprofiler
  paper_title: 'Language Models are Unsupervised Multitask Learners'
  authors:
  - Alec Radford
  - Jeffrey Wu
  - Rewon Child
  - David Luan
  - Dario Amodei
  - Ilya Sutskever
  year: 2019
  repo_url: https://github.com/huggingface/transformers
  extraction_method: trace-conversion
  extractor: codex-gpt5
  extraction_date: '2026-02-18'
  notes: 'Based on the Hugging Face transformers implementation of GPT-2, not the
    original OpenAI code. Profiled via dagprofiler to produce measured execution traces.
    DAG implementation repository: https://github.com/ANRGUSC/gpt2-dag. Profiler repository:
    https://github.com/ANRGUSC/dagprofiler. phase=prefill, prompt_len=128, decode_context_len=128,
    shard_count=12. Prefill and decode are complementary workflows for one request.
    Use prefill exactly once per prompt to initialize KV cache. Then run decode repeatedly
    for token generation steps. Total latency model used with this pair is: prefill_once
    + L_g * decode_step. For decode profiling, avg_kv is set to L_p + L_g/2 (here
    L_p=128, L_g=128). NOTE: The CCR (265961) is extremely high, meaning these workflows
    are heavily communication-dominated. Tensor sizes in bytes dwarf sub-millisecond
    compute times. Scheduling algorithms that assume CCR near 1.0 may behave
    differently on these workflows.'
license:
  source_license: Apache-2.0
  dagbench_license: Apache-2.0
  notes: Workflow representation generated from measured local profiling traces.
completeness: full
cost_model: deterministic
network:
  included: true
  topology: fully-connected
  num_nodes_min: 12
  num_nodes_max: 12
graph_stats:
  num_tasks: 327
  num_edges: 614
  depth: 63
  width: 12
  ccr: 265961.238438
  parallelism: 5.190476
campaign: campaign_006_gpt2_tensor_trace
tags:
- gpt2
- tensor-parallel
- sh12
- dagprofiler
- trace-conversion
- gpt2-dag
- prefill
